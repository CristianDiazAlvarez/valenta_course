{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df178d91-e4fb-4181-bb03-5f983d623477",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c161fd-5cb7-49b3-8814-d1eeefde91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec49f97c-8f24-42e5-91e8-b23c051ca99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb950303-f808-4a40-b706-9f3c554ce7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling data functions from file = 'mod02_data_functions.py', based on notebook md02\n",
    "from mod02_data_functions import get_mysql_cursor, list_mysql_databases_and_tables, create_covertype_table, delete_covertype_table,\\\n",
    "fetch_all_covertype_records, get_data_from_api, insert_unique_covertype_data, print_random_10_with_headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dce28c9-6b34-43cf-9f7b-c9eb72d3e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mod03A_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee349190-dd22-43dd-a461-6da62370fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mod04_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d2894-fa7d-47f7-9afc-6cc694552bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mysql_cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c7bb0-8b02-429a-a97d-69c95520649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mysql_databases_and_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf37f26-b01a-40bc-95b6-51c76865062b",
   "metadata": {},
   "source": [
    "## Remove previous tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262b412-923e-4c73-aab4-8d3b0346d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_covertype_table('raw_data')\n",
    "delete_covertype_table('clean_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab4d6de-24d8-4cbf-a632-0cdd7f2d6b3e",
   "metadata": {},
   "source": [
    "# Create Tables - Raw and Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23e4a3-83d8-48ab-9fa5-27c462c7f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_table = 'raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6fcff-59ea-41c7-8813-52c277fcbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_covertype_table(raw_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca1bd5-dc74-4770-acb3-c84fb15d348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_covertype_table(clean_data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f69b4-6c6c-4378-adde-ce07595d8f51",
   "metadata": {},
   "source": [
    "# Get data from API, save it into raw data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6436ee-34d7-4948-ae34-fd4be38ec782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get batch data from API\n",
    "group_number = 2 #there are 10 groups in total\n",
    "batch_data = get_data_from_api(group_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3dca3-7667-4403-8bf5-d89ec670176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save batch_data into raw data table\n",
    "insert_unique_covertype_data(batch_data, raw_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868e160-9b32-4c5d-8312-c12f0496adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate there is data in raw_table\n",
    "fetch_all_covertype_records(raw_data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b92907-f70b-44e3-8ad2-1fcdc1850621",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3a1df-4890-4245-8918-a6e2e879bcba",
   "metadata": {},
   "source": [
    "1. Data Cleaning\r\n",
    "Handle missing values: Although the dataset typically has no missing values, it's good practice to check\n",
    "\n",
    "2. Remove duplicates: Ensure no repeated rows.\n",
    "\n",
    "3. Feature Engineering\r\n",
    "Normalize distances: Scale distance-related features to reduce skew.\r\n",
    "\r\n",
    "Horizontal_Distance_To_Hydrology\r\n",
    "Vertical_Distance_To_Hydrology\r\n",
    "Horizontal_Distance_To_Roadways\r\n",
    "Horizontal_Distance_To_Fire_Points\r\n",
    "Hillshade interaction: Create a feature like average hil\n",
    "\n",
    "df['Hillshade_Avg'] = df[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].mean(axis=1)\r\n",
    "4. Encoding Categorical Variables\r\n",
    "Wilderness_Area and Soil_Type are categorical.\r\n",
    "Use One-Hot Encoding if using tree-based models.\r\n",
    "Use Label Encoding if using linear models or neural networ\n",
    "\n",
    "5. Feature Scaling\r\n",
    "Apply StandardScaler or MinMaxScaler to numerical features:\r\n",
    "Elevation, Aspect, Slope, et\n",
    "**************************************\n",
    "6. Train-Test Split\r\n",
    "Split the dataset before modeling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X = df.drop(\"Cover_Type\", axis=1)\r\n",
    "y = df[\"Cover_Type\"]\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    ":c.ks.\n",
    "lshade:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8f710-e2ad-4d4c-8488-77c2607861d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm packages\n",
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac6036-ebc8-480a-bf50-8114e998710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod03A_preprocessing.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a7ad4-12fb-4c9e-84e9-40f4318f376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = fetch_all_covertype_records('clean_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd2d7e-4617-400e-9c01-a3517a07b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_random_10_with_headers('clean_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e668a95-5a87-4def-8519-c96b8fceb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers\n",
    "\"\"\"raw_id  Elevation    Aspect     Slope  Hillshade_9am  Hillshade_Noon  Hillshade_3pm  Hillshade_Avg  Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  Horizontal_Distance_To_Fire_Points  Wilderness_Area_Cache  Wilderness_Area_Commanche  Wilderness_Area_Neota  Wilderness_Area_Rawah  Soil_Type_C2702  Soil_Type_C2703  Soil_Type_C2704  Soil_Type_C2705  Soil_Type_C2706  Soil_Type_C2717  Soil_Type_C3501  Soil_Type_C4201  Soil_Type_C4703  Soil_Type_C4704  Soil_Type_C4744  Soil_Type_C4758  Soil_Type_C6101  Soil_Type_C6102  Soil_Type_C6731  Soil_Type_C7101  Soil_Type_C7102  Soil_Type_C7103  Soil_Type_C7201  Soil_Type_C7202  Soil_Type_C7700  Soil_Type_C7702  Soil_Type_C7709  Soil_Type_C7710  Soil_Type_C7745  Soil_Type_C7746  Soil_Type_C7755  Soil_Type_C7756  Soil_Type_C7757  Soil_Type_C7790  Soil_Type_C8703  Soil_Type_C8708  Soil_Type_C8771  Soil_Type_C8772  Soil_Type_C8776  Cover_Type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb123b-cc4f-47ce-a657-a524d06bc493",
   "metadata": {},
   "source": [
    "# Training Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e36571-5149-4fe5-b6e5-d8cee8c5ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_cover_type_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7f4c5-cd6b-4930-9333-0253549dcba1",
   "metadata": {},
   "source": [
    "# MLFlow - register model and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877935b6-a1a4-42ec-b431-9a622533e5a7",
   "metadata": {},
   "source": [
    "***Rule of thumb - Conections between containers***\n",
    "\n",
    "a. Inside container-to-container communication (e.g., another service in the same Docker network): use container name and container port:\n",
    "\n",
    "\"http://mlflow:5000\"\n",
    "\n",
    "b. From host or anything outside Docker: use host port (5001 in your mapping):\n",
    "\n",
    "\"http://localhost:5001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74411fca-919f-4116-8131-0f3ac1955181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show mlflow\n",
    "%pip install --upgrade typing_extensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfe9ce-37b3-4fcd-b355-4dba796a5580",
   "metadata": {},
   "source": [
    "***IMPORTANT: install boto3 in jupyter***\n",
    "\n",
    "Even if your MLflow container has boto3, the client doing mlflow.sklearn.log_model() must also have it, because MLflow uploads artifacts directly from the client to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da5d97-9740-4a3c-90b1-22c52f06051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boto3 version in mlflow container: boto3: 1.40.2\n",
    "#installing the same version here in jupyter\n",
    "#%pip install boto3==1.40.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e5e2b-3f0c-4f6f-91c4-946aaba691a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import boto3\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a305d-07bf-4252-883d-7375c754b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "print(\"boto3 version:\", boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7ae0b-9fc1-405f-9163-86b1605bfe88",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757efe24-a0e3-4e24-9dd0-7a388eccacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loads the diabetes dataset\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "\n",
    "# Connect to MLflow tracking server defined in docker-compose file for mlflow service\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\") # docker-compose, mlflow service, ports: 5001:5000--> host:container\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"logged_artifacts\") as run:\n",
    "    params = {\"n_estimators\":50, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(\n",
    "      sk_model=rf,\n",
    "      artifact_path=\"random_forest_regressor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ed3d3-d93e-406c-a193-2620a7f3561b",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3381121-d511-4796-acf9-ab93e7cf8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial batch_data from group 2\n",
    "mod04_train_model.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bf580-493d-4abb-b58f-b73b2e386977",
   "metadata": {},
   "source": [
    "## Experiment 3 - adding new batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4766d-f3ee-4169-835b-e0100e478d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get batch data from API\n",
    "group_number = 2 #there are 10 groups in total\n",
    "batch_data = get_data_from_api(group_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b8027-5de6-44ca-97cf-ca072b92cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save batch_data into raw data table\n",
    "insert_unique_covertype_data(batch_data, raw_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc62519-5fc2-4079-b274-5fc29cdf537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate there is data in raw_table\n",
    "fetch_all_covertype_records(raw_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1bf18d-7630-4237-9625-8674a795f5f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod03A_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#PRE-PROCESSING - applied to new batch_data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmod03A_preprocessing\u001b[49m\u001b[38;5;241m.\u001b[39mmain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod03A_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "#PRE-PROCESSING - applied to new batch_data\n",
    "#this initial version is breaking the schema due to one/hot/encoder\n",
    "#mod03A_preprocessing.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b5afe80-4d92-4cac-bcb4-9d40a6f09b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing v2 of preprocessing module\n",
    "#this was refactored to skip one hot encoding, which was breaking the schema\n",
    "import mod03_preprocessing_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "621ae00a-7e49-4928-a4f1-fe6bde699045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL cursor created successfully\n",
      "Table 'clean_data' deleted if it existed.\n"
     ]
    }
   ],
   "source": [
    "#clearing old data\n",
    "delete_covertype_table('clean_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80025592-8514-46e8-babf-9018cc0cbcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL cursor created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/mod03_preprocessing_v2.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL cursor created successfully\n",
      "Inserted 2324 new processed rows into 'clean_data'.\n"
     ]
    }
   ],
   "source": [
    "#preprocessing with new version\n",
    "\n",
    "mod03_preprocessing_v2.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc24d015-3b63-4844-95c5-0b159317177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL cursor created successfully\n",
      "Accuracy: 0.7526881720430108\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75       174\n",
      "           1       0.76      0.77      0.76       213\n",
      "           2       0.87      0.85      0.86        40\n",
      "           3       1.00      0.50      0.67         2\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       1.00      0.33      0.50         9\n",
      "           6       0.79      0.69      0.73        16\n",
      "\n",
      "    accuracy                           0.75       465\n",
      "   macro avg       0.73      0.56      0.61       465\n",
      "weighted avg       0.74      0.75      0.74       465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025/08/08 19:30:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/08 19:30:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: 38fbfdfe13c9498c96746d9af9f9aa06\n",
      "🏃 View run RandomForest_CoverType at: http://mlflow:5000/#/experiments/2/runs/38fbfdfe13c9498c96746d9af9f9aa06\n",
      "🧪 View experiment at: http://mlflow:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "#Running experiment with new data\n",
    "mod04_train_model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ea70e-091e-48c0-93e2-45598fe51c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
